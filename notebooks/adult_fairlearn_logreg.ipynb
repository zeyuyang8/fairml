{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "UCI adult dataset with Fairlearn mitigator.\n",
    "\"\"\"\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.append('../')\n",
    "\n",
    "from fairlearn.reductions import DemographicParity\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from src.data.datasets import fetch_openml_dataset\n",
    "from src.models.fairlearn_mitigators import ExpGradMitigator\n",
    "from src.models.sklearn_estimators import SklearnClfs\n",
    "from src.eval.fairness import eval_binary_clf_fairness\n",
    "from src.models.fairlearn_mitigators import get_threshold_optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOGREG = \"Logistic regression\"\n",
    "LOGREG_DICT = {\n",
    "    LOGREG: LogisticRegression(max_iter=1000)\n",
    "}\n",
    "METRICS = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################################\n",
    "# Part 1 - ExpGradMitigator\n",
    "\n",
    "\n",
    "def uci_adult_exp_grad_pipline(sensitive, clfs_dict, constraint=DemographicParity()):\n",
    "    \"\"\"Run the pipeline for UCI adult dataset.\n",
    "\n",
    "    Args:\n",
    "        sensitive (str): sensitive feature\n",
    "        clfs_dict (dict): dictionary of classifiers\n",
    "        mitigator_name (str): name of the mitigator\n",
    "\n",
    "    Returns:\n",
    "        dict: dictionary of fairness metrics\n",
    "    \"\"\"\n",
    "    # Fetch dataset\n",
    "    uci_adult = fetch_openml_dataset(\"UCIadult\", sensitive)\n",
    "    X = uci_adult[\"features\"]\n",
    "    y_true = uci_adult[\"labels\"]\n",
    "    sensitive_features = uci_adult[\"sensitive\"]\n",
    "\n",
    "    # Fit classifiers\n",
    "    print(\"Fitting classifiers...\")\n",
    "    clfs = SklearnClfs(clfs_dict)\n",
    "    clfs.fit_estimator_all(X, y_true)\n",
    "    \n",
    "    # Fit mitigator\n",
    "    print(\"Fitting mitigators...\")\n",
    "    mitigators = ExpGradMitigator(clfs_dict, constraint)\n",
    "    mitigators.fit_estimator_all(X, y_true, sensitive_features=sensitive_features)\n",
    "\n",
    "    # Predict\n",
    "    y_pred = clfs.predict_all(X)\n",
    "    y_pred_mitigated = mitigators.predict_all(X)\n",
    "    \n",
    "    # Evaluate fairness\n",
    "    print(\"Evaluating fairness...\")\n",
    "    fairness = {}\n",
    "    fairness_mitigated = {}\n",
    "    for type in y_pred:\n",
    "        fairness[type] = eval_binary_clf_fairness(y_true, y_pred[type], sensitive_features)\n",
    "        fairness_mitigated[type] = eval_binary_clf_fairness(y_true, y_pred_mitigated[type], sensitive_features)\n",
    "\n",
    "    return fairness, fairness_mitigated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifiers...\n",
      "Fitting mitigators...\n",
      "Evaluating fairness...\n",
      "Logistic regression - Raw:\n",
      "accuracy               0.853528\n",
      "selection rate         0.195713\n",
      "true positive rate     0.602892\n",
      "false positive rate    0.067636\n",
      "dtype: object\n",
      "        accuracy  selection rate  true positive rate  false positive rate\n",
      "sex                                                                      \n",
      "Female  0.927866        0.075037            0.513284             0.021285\n",
      "Male    0.816662        0.255559            0.618875             0.097044\n",
      "\n",
      "Logistic regression - Exponentiated Gradient:\n",
      "accuracy               0.836698\n",
      "selection rate         0.164142\n",
      "true positive rate     0.501754\n",
      "false positive rate    0.057946\n",
      "dtype: object\n",
      "        accuracy  selection rate  true positive rate  false positive rate\n",
      "sex                                                                      \n",
      "Female  0.901927        0.153718            0.754664             0.080011\n",
      "Male    0.804349        0.169311            0.456644             0.043947\n"
     ]
    }
   ],
   "source": [
    "def test_uci_adult_exp_grad_pipline():\n",
    "    \"\"\"Test uci_adult_exp_grad_pipline function.\"\"\"\n",
    "    logreg_raw, logreg_expgrad_fair = uci_adult_exp_grad_pipline(\"sex\", LOGREG_DICT)\n",
    "    METRICS[\"raw\"] = logreg_raw\n",
    "    METRICS[\"expgrad\"] = logreg_expgrad_fair\n",
    "\n",
    "    stats_list = [\"accuracy\", \"selection rate\", \"true positive rate\", \"false positive rate\"]\n",
    "    print(f\"{LOGREG} - Raw:\")\n",
    "    print(METRICS[\"raw\"][LOGREG].overall[stats_list])\n",
    "    print(METRICS[\"raw\"][LOGREG].by_group[stats_list])\n",
    "    print()\n",
    "\n",
    "    print(f\"{LOGREG} - Exponentiated Gradient:\")\n",
    "    print(METRICS[\"expgrad\"][LOGREG].overall[stats_list])\n",
    "    print(METRICS[\"expgrad\"][LOGREG].by_group[stats_list])\n",
    "\n",
    "test_uci_adult_exp_grad_pipline()  # Takes ~ 40 seconds to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################################\n",
    "# Part 2 - ThresholdOptimizer\n",
    "\n",
    "\n",
    "def uci_adult_thrshd_optim_pipeline(sensitive, clfs_dict):\n",
    "    # Fetch dataset\n",
    "    uci_adult = fetch_openml_dataset(\"UCIadult\", sensitive)\n",
    "    X = uci_adult[\"features\"]\n",
    "    y_true = uci_adult[\"labels\"]\n",
    "    sensitive_features = uci_adult[\"sensitive\"]\n",
    "    \n",
    "    post_est_dict = get_threshold_optim(X, y_true, sensitive_features, clfs_dict)\n",
    "    y_pred_mitigated = {}\n",
    "    for mitigator_name in post_est_dict:\n",
    "        y_pred_mitigated[mitigator_name] = post_est_dict[mitigator_name].predict(\n",
    "            X, sensitive_features=sensitive_features\n",
    "        )\n",
    "    \n",
    "    # Evaluate fairness\n",
    "    print(\"Evaluating fairness...\")\n",
    "    fairness_mitigated = {}\n",
    "    for type in y_pred_mitigated:\n",
    "        fairness_mitigated[type] = eval_binary_clf_fairness(y_true,\n",
    "                                                            y_pred_mitigated[type],\n",
    "                                                            sensitive_features)\n",
    "    return fairness_mitigated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zeyuyang/opt/anaconda3/envs/fairml/lib/python3.9/site-packages/fairlearn/postprocessing/_threshold_optimizer.py:285: FutureWarning: 'predict_method' default value is changed from 'predict' to 'auto'. Explicitly pass `predict_method='predict' to replicate the old behavior, or pass `predict_method='auto' or other valid values to silence this warning.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fairness...\n",
      "Logistic regression - Threshold Optimizer:\n",
      "accuracy               0.800602\n",
      "selection rate         0.254945\n",
      "true positive rate     0.616069\n",
      "false positive rate    0.141354\n",
      "dtype: object\n",
      "        accuracy  selection rate  true positive rate  false positive rate\n",
      "sex                                                                      \n",
      "Female  0.768528        0.254632            0.605992             0.211537\n",
      "Male    0.816508        0.255100            0.617867             0.096824\n"
     ]
    }
   ],
   "source": [
    "def test_uci_adult_thrshd_optim_pipeline():\n",
    "    \"\"\"Test uci_adult_thrshd_optim_pipeline function.\"\"\"\n",
    "    logreg_th_optim = uci_adult_thrshd_optim_pipeline(\"sex\", LOGREG_DICT)\n",
    "    METRICS[\"th_optim\"] = logreg_th_optim\n",
    "    \n",
    "    stats_list = [\"accuracy\", \"selection rate\", \"true positive rate\", \"false positive rate\"]\n",
    "    print(f\"{LOGREG} - Threshold Optimizer:\")\n",
    "    print(METRICS[\"th_optim\"][LOGREG].overall[stats_list])\n",
    "    print(METRICS[\"th_optim\"][LOGREG].by_group[stats_list])\n",
    "\n",
    "\n",
    "test_uci_adult_thrshd_optim_pipeline()  # Takes ~ 40 seconds to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fairml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
